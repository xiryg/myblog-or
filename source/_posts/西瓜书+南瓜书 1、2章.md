---
title: 西瓜书+南瓜书 1-2章
tags: 机器学习
swiper_index: 13
categories: 机器学习
description: 西瓜书（绪论&模型评估与选择）
cover: 'https://img.tucang.cc/api/image/show/16d1c04d79e861b0cfde2872c823ee03'
date: '2024-06-18 20:05:08'
abbrlink: adaed5b0
---

# 第 1 章 绪论

## 1.1 什么是机器学习
-  机器学习就是把无序的数据转换成有用的信息。
-  研究关于 **"学习算法"**(一类能从数据中学习出其背后潜在规律的算法)  的学科。
-  **Tom M. Mitchell** 的定义：
> 一个计算机程序被认为能从经验E中学习，针对某些任务T和性能度量P，如果它在T类任务上的性能P随着经验E的增加而改进。
> -  **任务（T）**：垃圾邮件分类，即判定一封邮件是否为垃圾邮件。
> -  **性能度量（P）**：分类的准确率，即分类正确的邮件数量占总邮件数量的比例。
> -  **经验（E）**：一组带有标签的邮件数据集，其中每封邮件已经被标记为“垃圾邮件”或“正常邮件”。
> 
> 如果此垃圾分类程序通过越来越多的（经验E） 在（任务T）上面的（性能度量P）不断提高，能么则认为此程序从经验中学习了。

## 1.2 机器学习的基本术语
-  西瓜数据集

| 编号  | 色泽  | 根蒂  | 敲声  | 好瓜  |
| --- | --- | --- | --- | --- |
| 1   | 青绿  | 蜷缩  | 浊响  | 是   |
| 2   | 乌黑  | 蜷缩  | 浊响  | 是   |
| 3   | 青绿  | 硬挺  | 清脆  | 否   |
| 4   | 乌黑  | 稍蜷  | 沉闷  | 否   |

- **样本/示例**：上面一条数据集中的一条数据。
-  **属性/特征**：「色泽」「根蒂」「敲声」等。
-  **样本空间/属性空间/输入空间**：样本的特征向量所在的空间。
-  **特征向量**：空间中每个点对应的一个坐标向量。
-  **标记**：关于示例结果的信息，如（（色泽=青绿，根蒂=蜷缩，敲声=浊响），好瓜），其中「好瓜」称为标记。
-  **分类**：若要预测的是离散值，如「好瓜」，「坏瓜」，此类学习任务称为分类。
-  **回归**：若要预测的值是连续的，如 西瓜成熟度 0.95、0.37，此类学习任务成为回归。
-  **假设**：学得模型对应了关于数据的某种潜在规律。
-  **真相**：样本背后存在的潜在规律自身。
-  **学习过程**：是为了找出或逼近真相。
-  **泛化能力**：学得模型适用于新样本的能力。一般来说，训练样本越多，越有可能通过学习来获得具有强泛化能力的模型。
-  **监督学习** ：训练数据有标记信息，如「分类」和「回归」。
-  **非监督学习** ：训练数据不带有标记信息，如 「聚类」。

## 1.3 假设空间
-  假设空间：包含所有可能的**条件概率分布**或**决策函数**。

## 1.4 机器学习三要素
-  **模型**：根据具体问题，确定假设空间。
-  **策略**：根据评价标准，确定选取最优模型的策略（通常产出一个“损失函数”）。
-  **算法**：求解损失函数，确定最优模型。

*****

# 第2章 模型评估与选择

## 2.1 经验误差与过拟合
- **误差**：学习器对样本的实际预测结果与样本的真实值之间的差异。
- **训练误差**：在训练集上的误差。
- **测试误差**：在测试集上的误差。
- **泛化误差**：学习器在所有新样本上的误差。
- **过拟合**：学习器把训练样本不太一般的特性都学到了。
- **欠拟合**：学习器连训练样本的一般性质都未学好。
![](https://img.szgchw.cn/3263698676494340)

## 2.2 评估方法
- 评估方法的目的是选择泛化误差最小的学习器。

### 2.2.1 留出法
- 将数据集分为训练集和测试集，通常2/3-4/5的样本用作训练。
- 保持数据分布一致性，采用分层抽样。
- 重复随机划分，取平均值以提高稳定性。

### 2.2.2 交叉验证法
- 将数据集分为k个子集，进行k次训练和测试。
- 每次用k-1个子集训练，剩下的子集测试。
- 常用k值是10，称为10折交叉验证。
![](https://img.szgchw.cn/3263700924633115)

### 2.2.3 自助法
自助法是一种评估模型泛化能力的方法，适用于数据集较小的情况。

1. **数据集构建**：给定一个包含 $m$ 个样本的数据集 $D$ 。
2. **随机抽样**：从 $D$ 中随机挑选一个样本，将其拷贝放入新数据集 $D'$ ，然后将样本放回 $D$ ，以便在下一次抽样中仍有机会被选中。
3. **重复过程**：重复上述抽样过程 $m$ 次，得到新数据集 $D'$ ，它也包含 $m$ 个样本。
4. **概率计算**：在 $m$ 次抽样中，任何一个样本始终不被抽到的概率的极限是
$$\lim_{m \to \infty} \left(1 - \frac{1}{m}\right)^m = e^{-1} \approx 0.368$$
这意味着大约有36.8%的样本没有出现在\( D' \)中。
5. **训练与测试**：使用 $D'$ 作为训练集，而 $D$ 中未出现在 $D'$ 中的样本组成测试集。

### 2.2.4 调参与最终模型
- 学习算法有多个参数需要调节。
- 选定参数范围和步长，进行训练和评估。
- 调参完成后，使用整个数据集重新训练模型。

## 2.3 性能度量
- 性能度量用于评估模型的好坏。

### 2.3.1 错误率与精度
- **错误率**：分类错误的样本数占总样本数的比例。
- **精度**：分类正确的样本数占预测为正类的样本数的比例。


### 2.3.2 查准率、查全率与F1

在分类任务中，特别是在二分类问题中，查准率（Precision）和查全率（Recall）是两个重要的性能度量指标。它们的定义如下：
![](https://img.szgchw.cn/3263701595721754)


- **查准率（Precision）**：预测为正例且实际为正例的样本数占所有预测为正例样本数的比例。它反映了模型预测为正例中的准确率。
   $$\text{Precision} = \frac{TP}{TP + FP}$$ 
  其中，TP是真正例的数量，FP是假正例的数量。

- **查全率（Recall）**：预测为正例且实际为正例的样本数占所有实际为正例样本数的比例。反映了模型能够找出所有正例的能力。
 $$\text{Recall} = \frac{TP}{TP + FN}$$
  其中，FN是假反例的数量。

- **F1**：基于查准率和查全率的调和平均数，是两者的平衡指标，特别适用于查准率和查全率之间存在权衡的情况。
   $$F1 = 2 \times \frac{\text{P} \times \text{R}}{\text{P} + \text{R}}$$ 
*****
**参考文献**：
>  - 周志华. 机器学习[M]. 北京：清华大学出版社，2016.
>  - 李航. 统计学习方法[M]. 北京：清华大学出版社，2012.
>  - 视频资料：[第 1 章 绪论](https://www.bilibili.com/video/BV1Mh411e7VU?p=2)

